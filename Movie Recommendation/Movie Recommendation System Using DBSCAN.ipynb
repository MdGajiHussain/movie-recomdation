{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hi! Choosing a movie is a real struggle for many of us :) So most of the streaming platforms have inbuild recommendation systems. These systems aim to predict user's interests and recommend items that they'll probably like. Throughout this notebook, we will try to use 2 clasterisation methods to build our own movie recommender.\n",
    "\n",
    "#### We are going to use three following data sets:\n",
    "[Netflix TV Shows and Movies](https://www.kaggle.com/datasets/victorsoeiro/netflix-tv-shows-and-movies?datasetId=2178661&sortBy=voteCount)  \n",
    "[HBO Max TV Shows and Movies](https://www.kaggle.com/datasets/victorsoeiro/hbo-max-tv-shows-and-movies?select=titles.csv)  \n",
    "[Amazon Prime TV Shows and Movies](https://www.kaggle.com/datasets/victorsoeiro/amazon-prime-tv-shows-and-movies?select=titles.csv)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Libraries\n",
    "First, let's import the necessary libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data imports (3 datasets already mentioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix = pd.read_csv('Netflix TV Shows and Movies1.csv')\n",
    "df_amazon =  pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\Movie Recommendation\\Amazon Prime  and TV Shows  Movies1.csv\")\n",
    "df_hbo =  pd.read_csv('HBO Max TV Shows and Movies1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_netflix, df_amazon, df_hbo], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_movies.drop(['description', 'age_certification'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### working with production_countries column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             ['US']\n",
       "1             ['US']\n",
       "2             ['US']\n",
       "3             ['GB']\n",
       "4       ['GB', 'US']\n",
       "            ...     \n",
       "3289          ['PR']\n",
       "3290          ['PA']\n",
       "3291              []\n",
       "3292              []\n",
       "3293          ['US']\n",
       "Name: production_countries, Length: 19015, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['production_countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Remove unwanted characters from the 'production_countries' column\n",
    "# The .str.replace() method is used to remove '[' and ']' characters, and any single quotes\n",
    "# The 'regex=True' flag allows the .str.replace() method to interpret the patterns as regular expressions.\n",
    "# Note: Square brackets [ ] are special characters in regex, so they are not part of character set and needs escaping.\n",
    "df_movies['production_countries'] = df_movies['production_countries'].str.replace(r\"\\[\", '', regex=True).str.replace(r\"'\", '', regex=True).str.replace(r\"\\]\", '', regex=True)\n",
    "\n",
    "# 2. Extract the first country from the cleaned 'production_countries' column\n",
    "# The .str.split(',') splits the string into a list using commas as the delimiter, then .str[0] selects the first element.\n",
    "# This creates a new column 'lead_prod_country' that represents the primary production country of each movie\n",
    "df_movies['lead_prod_country'] = df_movies['production_countries'].str.split(',').str[0]\n",
    "\n",
    "# 3. Calculate the number of countries involved in the production of each movie\n",
    "# The .str.split(',') splits the 'production_countries' string by commas, and .str.len() counts the number of elements in the resulting list.\n",
    "# This new column 'prod_countries_cnt' stores the count of production countries for each movie, providing additional data insights\n",
    "df_movies['prod_countries_cnt'] = df_movies['production_countries'].str.split(',').str.len()\n",
    "\n",
    "# 4. Replace any empty values in the 'lead_prod_country' column with NaN (Not a Number)\n",
    "# This step uses the .replace() method to convert any empty strings ('') to np.nan (missing values)\n",
    "# Handling missing data with NaN is important for accurate data analysis and prevents errors in downstream processing\n",
    "df_movies['lead_prod_country'] = df_movies['lead_prod_country'].replace('', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        US\n",
       "1        US\n",
       "2        US\n",
       "3        GB\n",
       "4        GB\n",
       "       ... \n",
       "3289     PR\n",
       "3290     PA\n",
       "3291    NaN\n",
       "3292    NaN\n",
       "3293     US\n",
       "Name: lead_prod_country, Length: 18980, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['lead_prod_country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 ['documentation']\n",
       "1                                ['drama', 'crime']\n",
       "2       ['drama', 'action', 'thriller', 'european']\n",
       "3                   ['fantasy', 'action', 'comedy']\n",
       "4                                 ['war', 'action']\n",
       "                           ...                     \n",
       "3289                           ['romance', 'music']\n",
       "3290                                     ['comedy']\n",
       "3291                                     ['comedy']\n",
       "3292                                     ['comedy']\n",
       "3293                              ['documentation']\n",
       "Name: genres, Length: 18980, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove unwanted characters from the 'genres' column\n",
    "# The .str.replace() method is used to remove '[' and ']' characters, and any single quotes from the 'genres' column\n",
    "# This cleans the 'genres' data by removing extraneous characters, making it easier to analyze and manipulate\n",
    "# Note: Square brackets [ ] are special characters in regex, so they need escaping with a backslash (\\).\n",
    "df_movies['genres'] = df_movies['genres'].str.replace(r\"\\[\", '', regex=True).str.replace(r\"'\", '', regex=True).str.replace(r\"\\]\", '', regex=True)\n",
    "\n",
    "# 2. Extract the first genre from the cleaned 'genres' column\n",
    "# The .str.split(',') splits the 'genres' string by commas, and .str[0] selects the first element of the resulting list\n",
    "# This creates a new column 'main_genre' that represents the primary genre of each movie\n",
    "df_movies['main_genre'] = df_movies['genres'].str.split(',').str[0]\n",
    "\n",
    "# . Replace any empty values in the 'main_genre' column with NaN (Not a Number)\n",
    "# This step uses the .replace() method to convert any empty strings ('') to np.nan, indicating missing data\n",
    "# Handling missing data with NaN is important for accurate data analysis and prevents errors in downstream processing\n",
    "df_movies['main_genre'] = df_movies['main_genre'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       documentation\n",
       "1               drama\n",
       "2               drama\n",
       "3             fantasy\n",
       "4                 war\n",
       "            ...      \n",
       "3289          romance\n",
       "3290           comedy\n",
       "3291           comedy\n",
       "3292           comedy\n",
       "3293    documentation\n",
       "Name: main_genre, Length: 18980, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['main_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Drop unnecessary columns 'genres' and 'production_countries' from the DataFrame\n",
    "# The .drop() method with 'axis=1' removes specified columns, as they are no longer needed after extracting the main genre and production country count\n",
    "df_movies.drop(['genres', 'production_countries'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18980, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "title                     1\n",
       "type                      0\n",
       "release_year              0\n",
       "runtime                   0\n",
       "seasons               14772\n",
       "imdb_id                1394\n",
       "imdb_score             1873\n",
       "imdb_votes             1910\n",
       "tmdb_popularity         670\n",
       "tmdb_score             2656\n",
       "lead_prod_country      1160\n",
       "prod_countries_cnt        0\n",
       "main_genre              321\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values to clean the dataset\n",
    "df_movies.dropna(inplace=True)\n",
    "\n",
    "# Set the 'title' column as the DataFrame index\n",
    "df_movies.set_index('title', inplace=True)\n",
    "\n",
    "# Drop the 'id' and 'imdb_id' columns as they are not needed for further analysis\n",
    "df_movies.drop(['id', 'imdb_id'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>release_year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "      <th>tmdb_score</th>\n",
       "      <th>lead_prod_country</th>\n",
       "      <th>prod_countries_cnt</th>\n",
       "      <th>main_genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Monty Python's Flying Circus</th>\n",
       "      <td>SHOW</td>\n",
       "      <td>1969</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>73424.0</td>\n",
       "      <td>17.617</td>\n",
       "      <td>8.306</td>\n",
       "      <td>GB</td>\n",
       "      <td>1</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seinfeld</th>\n",
       "      <td>SHOW</td>\n",
       "      <td>1989</td>\n",
       "      <td>24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>308824.0</td>\n",
       "      <td>130.213</td>\n",
       "      <td>8.301</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knight Rider</th>\n",
       "      <td>SHOW</td>\n",
       "      <td>1982</td>\n",
       "      <td>51</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>34115.0</td>\n",
       "      <td>50.267</td>\n",
       "      <td>7.500</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>scifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thomas &amp; Friends</th>\n",
       "      <td>SHOW</td>\n",
       "      <td>1984</td>\n",
       "      <td>10</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>42.196</td>\n",
       "      <td>6.500</td>\n",
       "      <td>GB</td>\n",
       "      <td>1</td>\n",
       "      <td>animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saved by the Bell</th>\n",
       "      <td>SHOW</td>\n",
       "      <td>1989</td>\n",
       "      <td>23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>35034.0</td>\n",
       "      <td>19.855</td>\n",
       "      <td>8.000</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              type  release_year  runtime  seasons  \\\n",
       "title                                                                \n",
       "Monty Python's Flying Circus  SHOW          1969       30      4.0   \n",
       "Seinfeld                      SHOW          1989       24      9.0   \n",
       "Knight Rider                  SHOW          1982       51      4.0   \n",
       "Thomas & Friends              SHOW          1984       10     24.0   \n",
       "Saved by the Bell             SHOW          1989       23      5.0   \n",
       "\n",
       "                              imdb_score  imdb_votes  tmdb_popularity  \\\n",
       "title                                                                   \n",
       "Monty Python's Flying Circus         8.8     73424.0           17.617   \n",
       "Seinfeld                             8.9    308824.0          130.213   \n",
       "Knight Rider                         6.9     34115.0           50.267   \n",
       "Thomas & Friends                     6.5      5104.0           42.196   \n",
       "Saved by the Bell                    7.1     35034.0           19.855   \n",
       "\n",
       "                              tmdb_score lead_prod_country  \\\n",
       "title                                                        \n",
       "Monty Python's Flying Circus       8.306                GB   \n",
       "Seinfeld                           8.301                US   \n",
       "Knight Rider                       7.500                US   \n",
       "Thomas & Friends                   6.500                GB   \n",
       "Saved by the Bell                  8.000                US   \n",
       "\n",
       "                              prod_countries_cnt main_genre  \n",
       "title                                                        \n",
       "Monty Python's Flying Circus                   1     comedy  \n",
       "Seinfeld                                       1     comedy  \n",
       "Knight Rider                                   1      scifi  \n",
       "Thomas & Friends                               1  animation  \n",
       "Saved by the Bell                              1     family  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for categorical columns ('type', 'lead_prod_country', 'main_genre')\n",
    "dummies = pd.get_dummies(df_movies[['type', 'lead_prod_country', 'main_genre']], drop_first=True)\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df_movies_dum = pd.concat([df_movies, dummies], axis=1)\n",
    "\n",
    "# 14. Drop the original categorical columns after creating dummy variables\n",
    "df_movies_dum.drop(['type', 'lead_prod_country', 'main_genre'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling (MinmaxScaler):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply MinMaxScaler to scale the data for model training\n",
    "# scaler = MinMaxScaler()\n",
    "# df_scaled = scaler.fit_transform(df_movies_dum)\n",
    "\n",
    "# df_scaled = pd.DataFrame(df_scaled, columns=df_movies_dum.columns)\n",
    "\n",
    "# # Display the scaled DataFrame\n",
    "\n",
    "# df_scaled\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_movies_dum is already defined and not empty\n",
    "\n",
    "if not df_movies_dum.empty:\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = scaler.fit_transform(df_movies_dum)\n",
    "    df_scaled = pd.DataFrame(df_scaled, columns=df_movies_dum.columns)\n",
    "    \n",
    "    # Display the scaled DataFrame\n",
    "    df_scaled  # or just `df_scaled` in a notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "# step 4: DBSCAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### run a loop to get best epsilon value and minpnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For eps = 0.2 For min_samples = 5 Count clusters = 75 The average silhouette_score is : 0.43788407370982846\n",
      "For eps = 0.2 For min_samples = 10 Count clusters = 37 The average silhouette_score is : 0.36601440046646744\n",
      "For eps = 0.2 For min_samples = 30 Count clusters = 17 The average silhouette_score is : 0.2310605424719819\n",
      "For eps = 0.5 For min_samples = 5 Count clusters = 91 The average silhouette_score is : 0.6019560501740348\n",
      "For eps = 0.5 For min_samples = 10 Count clusters = 56 The average silhouette_score is : 0.530367943269805\n",
      "For eps = 0.5 For min_samples = 30 Count clusters = 21 The average silhouette_score is : 0.36228604161700473\n",
      "For eps = 1 For min_samples = 5 Count clusters = 93 The average silhouette_score is : 0.6091664186394286\n",
      "For eps = 1 For min_samples = 10 Count clusters = 57 The average silhouette_score is : 0.5362809971937991\n",
      "For eps = 1 For min_samples = 30 Count clusters = 22 The average silhouette_score is : 0.3712130038803749\n"
     ]
    }
   ],
   "source": [
    "# Define the range of epsilon (eps) and minimum samples (min_samples) parameters for DBSCAN\n",
    "eps_array = [0.2, 0.5, 1]  # List of different epsilon values (the maximum distance between two samples for one to be considered as in the neighborhood of the other)\n",
    "min_samples_array = [5, 10, 30]  # List of different min_samples values (the number of samples in a neighborhood for a point to be considered as a core point)\n",
    "\n",
    "# Iterate over each combination of eps and min_samples\n",
    "for eps in eps_array:\n",
    "    for min_samples in min_samples_array:\n",
    "        # Initialize and fit the DBSCAN model with the current parameters\n",
    "        clusterer = DBSCAN(eps=eps, min_samples=min_samples).fit(df_scaled)\n",
    "        \n",
    "        # Retrieve the cluster labels from the fitted model\n",
    "        cluster_labels = clusterer.labels_\n",
    "        \n",
    "        # Check if the algorithm found only one cluster or marked all points as noise (-1 label for noise)\n",
    "        if len(set(cluster_labels)) == 1:\n",
    "            continue  # Skip this combination as it does not provide meaningful clusters\n",
    "        \n",
    "        # Calculate the silhouette score to evaluate the quality of the clustering\n",
    "        silhouette_avg = silhouette_score(df_scaled, cluster_labels)\n",
    "        \n",
    "        # Print the current parameters, number of clusters, and the silhouette score\n",
    "        print(\"For eps =\", eps,\n",
    "              \"For min_samples =\", min_samples,\n",
    "              \"Count clusters =\", len(set(cluster_labels)),\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN With Best Hypterparameters (eps=1, minpnts=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For eps = 1 For min_samples = 5 Count clusters = 93 The average silhouette_score is : 0.6091664186394286\n"
     ]
    }
   ],
   "source": [
    "dbscan_model = DBSCAN(eps=1, min_samples=5).fit(df_scaled)\n",
    "print(\"For eps =\", 1,\n",
    "      \"For min_samples =\", 5,\n",
    "      \"Count clusters =\", len(set(dbscan_model.labels_)),\n",
    "      \"The average silhouette_score is :\", silhouette_score(df_scaled, dbscan_model.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save clusters for recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['dbscan_clusters'] = dbscan_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dbscan_clusters\n",
       "-1     387\n",
       " 1     347\n",
       " 13    267\n",
       " 35    221\n",
       " 5     145\n",
       "      ... \n",
       " 76      5\n",
       " 82      5\n",
       " 78      5\n",
       " 87      5\n",
       " 86      5\n",
       "Name: count, Length: 93, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['dbscan_clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "# Step 5: Movie Recommendation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our data is ready to use the clustering results to try and recommend a movie by the name of the one you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def recommend_movie(movie_name: str):\n",
    "    # Convert the input movie name to lowercase for case-insensitive matching\n",
    "    movie_name = movie_name.lower()\n",
    "\n",
    "    # Create a new column 'name' with lowercase movie names for comparison\n",
    "    df_movies['name'] = df_movies.index.str.lower()\n",
    "\n",
    "    # Find the movie that matches the input name\n",
    "    movie = df_movies[df_movies['name'].str.contains(movie_name, na=False)]\n",
    "\n",
    "    if not movie.empty:\n",
    "        # Get the cluster label of the input movie\n",
    "        cluster = movie['dbscan_clusters'].values[0]\n",
    "\n",
    "        # Get all movies in the same cluster\n",
    "        cluster_movies = df_movies[df_movies['dbscan_clusters'] == cluster]\n",
    "\n",
    "        # If there are more than 5 movies in the cluster, randomly select 5\n",
    "        if len(cluster_movies) >= 5:\n",
    "            recommended_movies = random.sample(list(cluster_movies.index), 5)\n",
    "        else:\n",
    "            # If fewer than 5, return all the movies in the cluster\n",
    "            recommended_movies = list(cluster_movies.index)\n",
    "\n",
    "        # Print the recommended movies\n",
    "        print('--- We can recommend you these movies ---')\n",
    "        for m in recommended_movies:\n",
    "            print(m)\n",
    "    else:\n",
    "        print('Movie not found in the database.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎉 Now we can input a random movie name and get 5 movies that our model recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = input('Input movie name: ')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "recommend_movie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input movie name: Vinland Saga\n",
      "\n",
      "\n",
      "\n",
      "--- We can recommend you these movies ---\n",
      "Kotaro Lives Alone\n",
      "Cowboy Bebop\n",
      "Hitorijime My Hero\n",
      "Vampire Knight\n",
      "Sailor Moon Crystal\n"
     ]
    }
   ],
   "source": [
    "s = input('Input movie name: ')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "recommend_movie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input movie name: Vampire Knight\n",
      "\n",
      "\n",
      "\n",
      "--- We can recommend you these movies ---\n",
      "Naruto\n",
      "Drifting Dragons\n",
      "Food Wars! Shokugeki no Soma\n",
      "Record of Ragnarok\n",
      "Beyblade Burst Surge\n"
     ]
    }
   ],
   "source": [
    "s = input('Input movie name: ')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "recommend_movie(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit App (so save df_movies dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.to_csv(\"clustered_movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
